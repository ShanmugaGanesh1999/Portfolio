# Scalability

> Designing systems that handle growth gracefully

---

## ğŸ“– What is Scalability?

**Scalability** is a system's ability to handle increased load by adding resources while maintaining (or improving) performance.

A scalable system can grow:
- **Users**: 1K â†’ 1M â†’ 1B users
- **Data**: 1GB â†’ 1TB â†’ 1PB storage
- **Traffic**: 100 â†’ 100K â†’ 100M requests/second

---

## ğŸ“Š Types of Scaling

### Vertical Scaling (Scale Up)

Add more power to existing machines.

```
Before:           After:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4 CPU   â”‚       â”‚ 32 CPU      â”‚
â”‚ 8GB RAM â”‚  â”€â”€â”€â–º â”‚ 256GB RAM   â”‚
â”‚ 500GB   â”‚       â”‚ 10TB SSD    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Pros**:
- Simple implementation
- No code changes needed
- No distributed system complexity

**Cons**:
- Hardware limits (can't scale infinitely)
- Single point of failure
- Expensive at high end
- Requires downtime to upgrade

### Horizontal Scaling (Scale Out)

Add more machines.

```
Before:                  After:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Server  â”‚       â”‚ Server  â”‚ â”‚ Server  â”‚ â”‚ Server  â”‚
â”‚    1    â”‚  â”€â”€â”€â–º â”‚    1    â”‚ â”‚    2    â”‚ â”‚    3    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Pros**:
- Near-infinite scalability
- No single point of failure
- Can use commodity hardware
- Can scale incrementally

**Cons**:
- More complex architecture
- Requires load balancing
- Data consistency challenges
- Network overhead

---

## ğŸ¯ Scalability Dimensions

### 1. Handling More Users

```
1 User           1000 Users        1M Users
   â”‚                  â”‚                â”‚
   â–¼                  â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ App â”‚         â”‚    LB     â”‚    â”‚   CDN/Edge   â”‚
â”‚ + DBâ”‚         â”‚ â”Œâ”€â”€â”€â”¬â”€â”€â”€â” â”‚    â”‚   â”Œâ”€â”€â”€â”€â”€â”    â”‚
â””â”€â”€â”€â”€â”€â”˜         â”‚ â”‚Appâ”‚Appâ”‚ â”‚    â”‚   â”‚ LB  â”‚    â”‚
                â”‚ â””â”€â”€â”€â”´â”€â”€â”€â”˜ â”‚    â”‚ â”Œâ”€â”´â”€â”¬â”€â”¬â”€â”´â”€â”  â”‚
                â”‚   â”Œâ”€â”€â”€â”   â”‚    â”‚ â”‚Appâ”‚Appâ”‚Appâ”‚â”‚
                â”‚   â”‚DB â”‚   â”‚    â”‚ â”‚Cacheâ”‚ â”‚ DBâ”‚â”‚
                â”‚   â””â”€â”€â”€â”˜   â”‚    â”‚ â”‚Clusterâ”‚    â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Handling More Data

```
Small Data (< 100GB)
â””â”€â–º Single database

Medium Data (100GB - 10TB)
â””â”€â–º Primary + Read replicas

Large Data (> 10TB)
â””â”€â–º Sharded database cluster

Massive Data (> 1PB)
â””â”€â–º Distributed data lake
```

### 3. Handling More Traffic

```
Low Traffic (< 100 RPS)
â””â”€â–º Single server

Medium Traffic (100 - 10K RPS)
â””â”€â–º Load balanced servers

High Traffic (10K - 1M RPS)
â””â”€â–º Multi-layer caching + LB

Extreme Traffic (> 1M RPS)
â””â”€â–º Edge computing + CDN + sharding
```

---

## ğŸ”§ Scalability Patterns

### 1. Load Balancing

Distribute traffic across multiple servers.

```
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚Load Balancer â”‚
             â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼          â–¼          â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚Server 1â”‚ â”‚Server 2â”‚ â”‚Server 3â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Algorithms**:
- Round Robin: Rotate through servers
- Least Connections: Send to least busy
- IP Hash: Consistent routing by client IP
- Weighted: More traffic to more powerful servers

### 2. Database Replication

Scale reads by adding replicas.

```
        Writes
           â”‚
           â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚Primary â”‚
      â”‚   DB   â”‚
      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”
   â–¼       â–¼       â–¼
â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”
â”‚Read â”‚ â”‚Read â”‚ â”‚Read â”‚
â”‚Rep 1â”‚ â”‚Rep 2â”‚ â”‚Rep 3â”‚
â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜
   â–²       â–²       â–²
   â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
         Reads
```

### 3. Database Sharding

Partition data across multiple databases.

```
User ID: 12345
Shard = hash(12345) % 4 = 1

Shard 0        Shard 1        Shard 2        Shard 3
Users 0,4,8    Users 1,5,9    Users 2,6,10   Users 3,7,11
   ...            ...            ...            ...
```

**Sharding Strategies**:
- **Hash-based**: hash(key) % num_shards
- **Range-based**: A-M on shard1, N-Z on shard2
- **Geographic**: Users by region
- **Tenant-based**: Each customer on own shard

### 4. Caching

Reduce database load with in-memory cache.

```
Request Flow:
1. Check cache â†’ HIT â†’ Return cached data
       â”‚
       â””â”€â”€ MISS
              â”‚
              â–¼
2. Query database
3. Store in cache
4. Return data
```

**Caching Layers**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ L1: Browser Cache (client-side)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ L2: CDN Cache (edge)                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ L3: Application Cache (Redis/Memcached)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ L4: Database Cache (query cache)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5. Asynchronous Processing

Handle spikes with message queues.

```
Synchronous (blocks):
User â†’ API â†’ Process â†’ DB â†’ Response

Asynchronous (returns immediately):
User â†’ API â†’ Queue â†’ Response
               â”‚
               â–¼ (async)
           Worker â†’ DB
```

### 6. CDN (Content Delivery Network)

Serve static content from edge locations.

```
Without CDN:
User (Tokyo) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Server (New York)
              Long distance, slow

With CDN:
User (Tokyo) â”€â”€â–º CDN Edge (Tokyo) â”€â”€â–º Server (New York)
              Fast!            Only if cache miss
```

---

## ğŸ“ˆ Scaling Strategies by Component

### Scaling the Web Layer

```
Strategy: Stateless servers + Load balancer

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    LB    â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
  â”Œâ”€â”€â”´â”€â”€â”
  â–¼     â–¼
â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â”   Stateless!
â”‚ S â”‚ â”‚ S â”‚   Any server can
â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜   handle any request

Session data stored externally (Redis)
```

### Scaling the Database Layer

```
Read-heavy:    Add read replicas
Write-heavy:   Shard the database
Both:          Combination + caching

Evolution:
1. Single DB
2. Primary + Replicas
3. Sharded Primary + Replicas per shard
4. Multi-region clusters
```

### Scaling the Cache Layer

```
Single Cache:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Redis      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Clustered Cache:
â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”
â”‚Redis 1â”‚ â”‚Redis 2â”‚ â”‚Redis 3â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       Consistent Hashing
```

---

## âš ï¸ Scalability Challenges

### 1. Stateful Services

```
Problem: Server stores user session
         User routed to different server â†’ Lost state

Solutions:
â”œâ”€â”€ Sticky sessions (route same user to same server)
â”œâ”€â”€ External session store (Redis)
â””â”€â”€ Stateless design (JWT tokens)
```

### 2. Database Bottlenecks

```
Symptoms:
â”œâ”€â”€ Slow queries
â”œâ”€â”€ Connection pool exhaustion
â”œâ”€â”€ High CPU on DB server

Solutions:
â”œâ”€â”€ Query optimization
â”œâ”€â”€ Indexing
â”œâ”€â”€ Read replicas
â”œâ”€â”€ Caching
â”œâ”€â”€ Sharding
â””â”€â”€ Switch to appropriate DB type
```

### 3. Hotspots

```
Problem: Uneven load distribution

Celebrity with 100M followers posts
â””â”€â–º All reads hit same shard

Solutions:
â”œâ”€â”€ Add redundant copies for hot data
â”œâ”€â”€ Use cache more aggressively
â””â”€â”€ Distribute across more shards
```

### 4. Cross-Shard Operations

```
Problem: Query needs data from multiple shards

"SELECT * FROM orders WHERE user_id IN (1, 5, 9)"
                                          â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â–¼
Shard 0: user 1
Shard 1: user 5
Shard 2: user 9

Solutions:
â”œâ”€â”€ Query all shards in parallel
â”œâ”€â”€ Scatter-gather pattern
â””â”€â”€ Denormalize to avoid cross-shard
```

---

## ğŸ“Š Scaling Numbers

### Quick Estimation Guide

| Component | Single Instance | Scaled |
|-----------|----------------|--------|
| Web Server | ~1K RPS | ~50K RPS (50 servers) |
| MySQL | ~5K RPS | ~100K RPS (sharded) |
| Redis | ~100K RPS | ~1M RPS (clustered) |
| Elasticsearch | ~10K RPS | ~100K RPS (clustered) |

### Traffic Examples

| Scale | Example | Architecture |
|-------|---------|--------------|
| Small | Blog | 1 server, 1 DB |
| Medium | Startup | LB + 3 servers + DB + Cache |
| Large | Twitter | Thousands of servers, multiple DCs |
| Massive | Google | Millions of servers, custom everything |

---

## ğŸ› ï¸ Auto-Scaling

### Horizontal Auto-Scaling

```python
# Pseudo-code for auto-scaling policy
def check_scaling():
    cpu_usage = get_average_cpu()
    
    if cpu_usage > 80%:
        add_instances(2)
    elif cpu_usage < 30% and instance_count > min_instances:
        remove_instances(1)
```

### Scaling Metrics

```
Scale based on:
â”œâ”€â”€ CPU utilization
â”œâ”€â”€ Memory usage
â”œâ”€â”€ Request queue length
â”œâ”€â”€ Request latency
â”œâ”€â”€ Custom application metrics
â””â”€â”€ Time of day (predictive)
```

---

## ğŸ’¡ Interview Tips

### Questions to Ask
1. What's the expected user growth?
2. What's the read:write ratio?
3. Are there traffic spikes (e.g., events)?
4. What's the data growth rate?
5. What's the latency budget?

### Points to Discuss
1. Start simple, scale as needed
2. Identify bottlenecks first
3. Scale the right component
4. Consider cost implications
5. Plan for failure during scaling

---

## âœ… Key Takeaways

1. **Scale what matters** - Identify bottlenecks first
2. **Horizontal > Vertical** - For true scalability
3. **Stateless is key** - Enables easy horizontal scaling
4. **Cache aggressively** - Reduce database load
5. **Shard when necessary** - But it adds complexity
6. **Async for spikes** - Queue work, process later
7. **Monitor and measure** - Can't improve what you don't measure
