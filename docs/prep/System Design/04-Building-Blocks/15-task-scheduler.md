# Task Scheduler

> Executing jobs reliably at scale

---

## ğŸ“– What is a Task Scheduler?

A **Task Scheduler** is a system that manages the execution of jobs/tasks at specified times or intervals, ensuring reliable completion even in distributed environments.

```
Types of Tasks:
â”œâ”€â”€ Scheduled: Run at specific time (cron)
â”œâ”€â”€ Recurring: Run periodically (every hour)
â”œâ”€â”€ Delayed: Run after X time (remind in 1 hour)
â””â”€â”€ Event-triggered: Run when event occurs
```

---

## ğŸ¯ Why Task Scheduling?

```
Use Cases:
â”œâ”€â”€ Send email digests every morning
â”œâ”€â”€ Process pending payments every 5 minutes
â”œâ”€â”€ Generate reports at end of day
â”œâ”€â”€ Expire sessions after 30 minutes
â”œâ”€â”€ Retry failed operations
â”œâ”€â”€ Batch processing jobs
â””â”€â”€ Cleanup old data

Challenges in Distributed Systems:
â”œâ”€â”€ Multiple instances â†’ duplicate execution
â”œâ”€â”€ Server failure â†’ missed jobs
â”œâ”€â”€ Time zones and daylight saving
â”œâ”€â”€ Job dependencies
â””â”€â”€ Scaling under load
```

---

## ğŸ”§ Scheduler Architecture

### Basic Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Task Scheduler                           â”‚
â”‚                                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                           â”‚
â”‚   â”‚  Job Store  â”‚ â† Persistence (what jobs exist)           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                           â”‚
â”‚          â”‚                                                   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                                           â”‚
â”‚   â”‚  Scheduler  â”‚ â† Decides when to run                     â”‚
â”‚   â”‚   (Timer)   â”‚                                           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                           â”‚
â”‚          â”‚                                                   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                                           â”‚
â”‚   â”‚   Queue     â”‚ â† Jobs ready to execute                   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                           â”‚
â”‚          â”‚                                                   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                                           â”‚
â”‚   â”‚   Workers   â”‚ â† Execute the jobs                        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Distributed Architecture

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Job Store     â”‚
                    â”‚   (Database)    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼              â–¼              â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚Scheduler 1â”‚  â”‚Scheduler 2â”‚  â”‚Scheduler 3â”‚
       â”‚  (Leader) â”‚  â”‚(Standby)  â”‚  â”‚(Standby)  â”‚
       â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚        Task Queue           â”‚
       â”‚    (Redis / RabbitMQ)       â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â–¼          â–¼          â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”
       â”‚Worker1â”‚  â”‚Worker2â”‚  â”‚Worker3â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Scheduling Strategies

### Cron-based

```
Standard cron expression:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ minute (0 - 59)
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ hour (0 - 23)
â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ day of month (1 - 31)
â”‚ â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ month (1 - 12)
â”‚ â”‚ â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ day of week (0 - 6)
â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ â”‚ â”‚
* * * * *

Examples:
0 9 * * *     â†’ Every day at 9:00 AM
*/15 * * * *  â†’ Every 15 minutes
0 0 1 * *     â†’ First day of every month
0 8-17 * * 1-5 â†’ Hourly, 8AM-5PM, weekdays
```

### Fixed Delay vs Fixed Rate

```
Fixed Rate (every 5 min regardless of duration):
â”œâ”€â”€ Run at: 00:00, 00:05, 00:10, 00:15
â”œâ”€â”€ Even if job takes 3 minutes
â””â”€â”€ Risk: Overlapping jobs

Timeline:
00:00 â”€â”€â”€â”€[job 3min]â”€â”€â”€â”€ 00:03
00:05 â”€â”€â”€â”€[job 3min]â”€â”€â”€â”€ 00:08
00:10 â”€â”€â”€â”€[job 3min]â”€â”€â”€â”€ 00:13

Fixed Delay (5 min after previous completes):
â”œâ”€â”€ Finish â†’ Wait 5 min â†’ Start
â”œâ”€â”€ More predictable
â””â”€â”€ Longer total cycle

Timeline:
00:00 â”€â”€â”€â”€[job 3min]â”€â”€â”€â”€ 00:03 â”€â”€5minâ”€â”€ 00:08 â”€â”€â”€â”€[job]â”€â”€â”€â”€
```

### Priority Scheduling

```
High Priority: Process now, skip queue
Medium Priority: Normal queue
Low Priority: Run when idle

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     High    â”‚    Medium    â”‚  Low   â”‚
â”‚  [â”€â”€â”€â”€â”€â”€â”€]  â”‚  [â”€â”€â”€â”€â”€â”€â”€â”€â”€] â”‚  [â”€â”€]  â”‚
â”‚   Process   â”‚     Wait     â”‚  Idle  â”‚
â”‚    first    â”‚              â”‚        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Ensuring Exactly-Once Execution

### The Problem

```
Multiple scheduler instances:
â”œâ”€â”€ Instance A: "Time to run job X!"
â”œâ”€â”€ Instance B: "Time to run job X!"
â””â”€â”€ Job runs twice! âŒ
```

### Solution 1: Leader Election

```
Only one scheduler is active:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Leader Election                 â”‚
â”‚                                          â”‚
â”‚   Scheduler A â—„â”€â”€â”€ Leader (runs jobs)    â”‚
â”‚   Scheduler B â—„â”€â”€â”€ Follower (standby)    â”‚
â”‚   Scheduler C â—„â”€â”€â”€ Follower (standby)    â”‚
â”‚                                          â”‚
â”‚   If A dies â†’ B becomes leader           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Use: ZooKeeper, etcd, Redis SETNX
```

### Solution 2: Distributed Locking

```python
# Each job acquires lock before running
import redis
import time

def run_job_with_lock(redis_client, job_id, job_func):
    lock_key = f"job_lock:{job_id}"
    lock_value = str(uuid.uuid4())
    
    # Try to acquire lock (atomic)
    acquired = redis_client.set(
        lock_key, 
        lock_value,
        nx=True,  # Only if not exists
        ex=300    # Expire in 5 minutes (safety)
    )
    
    if not acquired:
        return "Job already running"
    
    try:
        job_func()
    finally:
        # Release lock (only if we own it)
        lua_script = """
        if redis.call("get", KEYS[1]) == ARGV[1] then
            return redis.call("del", KEYS[1])
        else
            return 0
        end
        """
        redis_client.eval(lua_script, 1, lock_key, lock_value)
```

### Solution 3: Database-based Locking

```sql
-- Job table with lock
CREATE TABLE scheduled_jobs (
    id VARCHAR(50) PRIMARY KEY,
    next_run_at TIMESTAMP,
    locked_by VARCHAR(50) NULL,
    locked_until TIMESTAMP NULL
);

-- Worker claims job atomically
UPDATE scheduled_jobs 
SET locked_by = 'worker-1',
    locked_until = NOW() + INTERVAL '5 minutes'
WHERE id = 'job-123'
  AND (locked_by IS NULL OR locked_until < NOW())
  AND next_run_at <= NOW();
  
-- If UPDATE affected 1 row â†’ we got the lock
-- If UPDATE affected 0 rows â†’ someone else has it
```

---

## ğŸ“ˆ Job Execution Patterns

### Retry with Backoff

```
Failure handling:

Attempt 1: Run job      â†’ Failed
Wait: 1 second
Attempt 2: Retry        â†’ Failed
Wait: 2 seconds
Attempt 3: Retry        â†’ Failed
Wait: 4 seconds
Attempt 4: Retry        â†’ Failed
Wait: 8 seconds
Attempt 5: Retry        â†’ Success âœ“

Or: Max retries exceeded â†’ Dead letter queue
```

```python
import time
from functools import wraps

def retry_with_backoff(max_retries=5, base_delay=1):
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if attempt == max_retries - 1:
                        raise  # Final attempt failed
                    
                    delay = base_delay * (2 ** attempt)
                    time.sleep(delay)
        return wrapper
    return decorator

@retry_with_backoff(max_retries=5)
def process_payment(order_id):
    # May fail, will be retried
    pass
```

### Job State Machine

```
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                                     â”‚
         â–¼                                     â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ PENDING â”‚â”€â”€â”€â”€â–ºâ”‚ RUNNING â”‚â”€â”€â”€â”€â–ºâ”‚ SUCCESS â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚               â”‚
         â”‚               â–¼
         â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚          â”‚ FAILED  â”‚â”€â”€â”€â”€â–ºâ”‚  RETRY  â”‚â”€â”€â”€â”
         â”‚          â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
         â”‚               â”‚                        â”‚
         â”‚               â–¼                        â”‚
         â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  DEAD   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚ LETTER  â”‚   (max retries)
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Delayed Job Execution

### Database Polling

```
Simple but not efficient for many jobs:

SELECT * FROM jobs 
WHERE run_at <= NOW() 
  AND status = 'pending'
ORDER BY run_at
LIMIT 100;

Problem: Polling overhead, delay between polls
```

### Redis Sorted Sets

```
Score = timestamp when job should run:

ZADD delayed_jobs 1705320000 "job:123"  # Run at timestamp
ZADD delayed_jobs 1705320060 "job:124"  # Run 1 min later

Worker:
while True:
    # Get jobs ready to run
    jobs = ZRANGEBYSCORE delayed_jobs 0 NOW LIMIT 0 10
    for job in jobs:
        # Process and remove
        ZREM delayed_jobs job
        process(job)
```

### Timing Wheel

```
Efficient for many short delays:

Wheel with 60 slots (seconds):
    
     0   1   2   3   4   5   ...  59
    [â—] [ ] [â—] [ ] [â—] [ ] ... [â—]
     â”‚       â”‚       â”‚           â”‚
     â””â”€jobs  â””â”€jobs  â””â”€jobs      â””â”€jobs
     
Current pointer advances each second
Process all jobs in current slot

For longer delays: Hierarchical wheels
â”œâ”€â”€ Seconds wheel (60 slots)
â”œâ”€â”€ Minutes wheel (60 slots)  
â””â”€â”€ Hours wheel (24 slots)
```

---

## ğŸ“Š Task Scheduling Technologies

### Celery (Python)

```python
from celery import Celery
from celery.schedules import crontab

app = Celery('tasks', broker='redis://localhost')

# Periodic tasks
app.conf.beat_schedule = {
    'send-report-every-morning': {
        'task': 'tasks.send_report',
        'schedule': crontab(hour=9, minute=0),
    },
    'cleanup-every-hour': {
        'task': 'tasks.cleanup',
        'schedule': crontab(minute=0),
    },
}

@app.task
def send_report():
    # Generate and send report
    pass

# Delayed task
send_email.apply_async(args=['hello'], countdown=3600)  # 1 hour
```

### Bull (Node.js)

```javascript
const Queue = require('bull');

const emailQueue = new Queue('email', 'redis://localhost');

// Add job with delay
emailQueue.add(
    { to: 'user@email.com', subject: 'Hello' },
    { delay: 3600000 }  // 1 hour in ms
);

// Recurring job
emailQueue.add(
    { type: 'daily-report' },
    { repeat: { cron: '0 9 * * *' } }
);

// Process jobs
emailQueue.process(async (job) => {
    await sendEmail(job.data);
});
```

### Comparison

| Feature | Celery | Bull | Sidekiq |
|---------|--------|------|---------|
| Language | Python | Node.js | Ruby |
| Broker | Redis/RabbitMQ | Redis | Redis |
| Cron | Yes (Beat) | Yes | Yes |
| Priorities | Yes | Yes | Yes |
| Retries | Yes | Yes | Yes |
| Dashboard | Flower | Bull Board | Web UI |

### Enterprise Options

```
AWS:
â”œâ”€â”€ SQS + Lambda (serverless)
â”œâ”€â”€ Step Functions (complex workflows)
â”œâ”€â”€ EventBridge (scheduled events)

Google Cloud:
â”œâ”€â”€ Cloud Tasks
â”œâ”€â”€ Cloud Scheduler
â””â”€â”€ Cloud Functions

Kubernetes:
â”œâ”€â”€ CronJobs (built-in)
â”œâ”€â”€ Argo Workflows
â””â”€â”€ Temporal.io
```

---

## ğŸ’¡ Handling Job Dependencies

### DAG (Directed Acyclic Graph)

```
Job dependencies as graph:

        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Extract  â”‚
        â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼         â–¼         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”
â”‚Transformâ”‚Transformâ”‚Transform
â”‚   A    â”‚   B    â”‚   C    â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜â””â”€â”€â”€â”¬â”€â”€â”€â”˜â””â”€â”€â”€â”¬â”€â”€â”€â”˜
    â”‚         â”‚        â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Load   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Tools: Airflow, Dagster, Prefect
```

### Workflow Example (Airflow)

```python
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime

dag = DAG(
    'etl_pipeline',
    schedule_interval='0 2 * * *',  # 2 AM daily
    start_date=datetime(2024, 1, 1)
)

extract = PythonOperator(
    task_id='extract',
    python_callable=extract_data,
    dag=dag
)

transform = PythonOperator(
    task_id='transform',
    python_callable=transform_data,
    dag=dag
)

load = PythonOperator(
    task_id='load',
    python_callable=load_data,
    dag=dag
)

# Define dependencies
extract >> transform >> load
```

---

## ğŸ’¡ In System Design Interviews

### When to Discuss

```
1. "How do you send reminder emails?"
2. "How do you handle recurring tasks?"
3. "How do you retry failed operations?"
4. "How do you process data in batches?"
```

### Key Points

```
1. Exactly-once: Leader election or distributed locks
2. Persistence: Jobs stored in database
3. Queue: For distributing work
4. Retries: Exponential backoff
5. Dead letter: For failed jobs
6. Monitoring: Job success/failure rates
7. Scaling: More workers for throughput
```

---

## âœ… Key Takeaways

1. **Job store** for persistence
2. **Leader election** or **distributed locks** for exactly-once
3. **Queue** to distribute work to workers
4. **Retry with backoff** for failures
5. **Dead letter queue** for max-retried jobs
6. **Celery/Bull** for application-level scheduling
7. **Airflow** for complex DAG workflows
8. **Kubernetes CronJobs** for container workloads
