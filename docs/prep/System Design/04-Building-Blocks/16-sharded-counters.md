# Sharded Counters

> Counting at massive scale without bottlenecks

---

## ğŸ“– What is a Sharded Counter?

A **Sharded Counter** distributes a single counter across multiple shards to avoid contention and enable high-throughput writes.

```
Problem: Single counter bottleneck

All writes to one row:
Thread 1 â”€â”
Thread 2 â”€â”¼â”€â”€â–º [counter: 1234] â† Lock contention!
Thread 3 â”€â”˜

Solution: Spread across shards

Thread 1 â”€â”€â–º [shard_0: 400]
Thread 2 â”€â”€â–º [shard_1: 412]  â”€â”€â–º Total = 1234
Thread 3 â”€â”€â–º [shard_2: 422]
```

---

## ğŸ¯ When to Use

```
Use Cases:
â”œâ”€â”€ Like counts on viral posts
â”œâ”€â”€ View counts on popular videos
â”œâ”€â”€ Real-time vote counting
â”œâ”€â”€ Global visitor counters
â”œâ”€â”€ API rate limit counters
â””â”€â”€ Inventory decrements (flash sales)

Symptoms you need sharding:
â”œâ”€â”€ Database CPU spikes on counter updates
â”œâ”€â”€ Lock wait timeouts
â”œâ”€â”€ Slow writes during peak traffic
â””â”€â”€ Single row becoming hot spot
```

---

## ğŸ”§ How It Works

### Basic Concept

```
Instead of:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ post_id â”‚ like_count    â”‚
â”‚   123   â”‚   1,000,000   â”‚ â† Hot row
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Use:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ post_id â”‚ shard_id â”‚ count         â”‚
â”‚   123   â”‚    0     â”‚   100,523     â”‚
â”‚   123   â”‚    1     â”‚    99,847     â”‚
â”‚   123   â”‚    2     â”‚   100,102     â”‚
â”‚   ...   â”‚   ...    â”‚     ...       â”‚
â”‚   123   â”‚    9     â”‚    99,428     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Total likes = SUM(count) WHERE post_id = 123
            = 1,000,000
```

### Increment Operation

```python
import random

NUM_SHARDS = 10

def increment_counter(post_id):
    # Randomly pick a shard
    shard_id = random.randint(0, NUM_SHARDS - 1)
    
    # Increment that shard
    db.execute("""
        INSERT INTO counters (post_id, shard_id, count)
        VALUES (%s, %s, 1)
        ON CONFLICT (post_id, shard_id)
        DO UPDATE SET count = counters.count + 1
    """, (post_id, shard_id))

def get_counter(post_id):
    # Sum all shards
    result = db.execute("""
        SELECT SUM(count) FROM counters
        WHERE post_id = %s
    """, (post_id,))
    return result[0] or 0
```

### Write Distribution

```
With 10 shards:
â”œâ”€â”€ Each shard gets ~10% of writes
â”œâ”€â”€ 10x reduction in contention per shard
â””â”€â”€ Scale by adding more shards

Write pattern (random distribution):

Request 1 â”€â”€â”€â”€â”€â–º Shard 7 â”€â”
Request 2 â”€â”€â”€â”€â”€â–º Shard 2  â”‚
Request 3 â”€â”€â”€â”€â”€â–º Shard 9  â”œâ”€â”€â–º Sum on read
Request 4 â”€â”€â”€â”€â”€â–º Shard 2  â”‚
Request 5 â”€â”€â”€â”€â”€â–º Shard 5 â”€â”˜
```

---

## ğŸ“Š Choosing Number of Shards

```
Too few shards:
â”œâ”€â”€ Still have contention
â””â”€â”€ Limited scalability

Too many shards:
â”œâ”€â”€ More rows to aggregate
â”œâ”€â”€ Higher read cost
â””â”€â”€ More complexity

Heuristics:
â”œâ”€â”€ Start with 10-100 shards
â”œâ”€â”€ Shards >= expected writes per second
â”œâ”€â”€ More shards for viral content
â””â”€â”€ Can dynamically adjust

Example:
â”œâ”€â”€ Normal post: 10 shards
â”œâ”€â”€ Trending post: 100 shards
â””â”€â”€ Viral post: 1000 shards
```

---

## ğŸ”§ Shard Selection Strategies

### Random

```python
# Simple, good distribution
shard_id = random.randint(0, NUM_SHARDS - 1)

Pros:
â”œâ”€â”€ Even distribution
â””â”€â”€ Simple implementation

Cons:
â”œâ”€â”€ Not deterministic
â””â”€â”€ Can't do per-user dedup easily
```

### Hash-based

```python
# Deterministic based on input
shard_id = hash(user_id) % NUM_SHARDS

Pros:
â”œâ”€â”€ Deterministic
â”œâ”€â”€ Same user â†’ same shard
â””â”€â”€ Can track per-user actions

Cons:
â”œâ”€â”€ May have uneven distribution
â””â”€â”€ Hot users still cause problems
```

### Round-robin (with counter)

```python
# Rotate through shards
import redis

def get_next_shard(counter_id):
    shard = redis.incr(f"shard_counter:{counter_id}")
    return shard % NUM_SHARDS

Pros:
â”œâ”€â”€ Even distribution
â”œâ”€â”€ Predictable

Cons:
â”œâ”€â”€ Requires coordination
â””â”€â”€ Extra Redis call
```

---

## ğŸ“ˆ Optimizing Reads

### Problem: Reads Still Slow

```
Every read = SUM across all shards
10 shards = 10 rows to aggregate

For hot content, this is still slow!
```

### Solution 1: Cached Total

```
Periodically aggregate and cache:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Shards (DB)  â”‚     â”‚        Redis             â”‚
â”‚ [100] [99]   â”‚â”€â”€â”€â”€â–ºâ”‚ post:123:likes = 1000000 â”‚
â”‚ [101] [100]  â”‚     â”‚ (cached, TTL: 1 minute)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Read path:
1. Check cache â†’ if hit, return
2. Cache miss â†’ aggregate from DB
3. Cache the result
```

```python
def get_likes(post_id):
    # Try cache first
    cached = redis.get(f"likes:{post_id}")
    if cached:
        return int(cached)
    
    # Cache miss - aggregate from DB
    total = db.execute(
        "SELECT SUM(count) FROM counters WHERE post_id = %s",
        (post_id,)
    )[0]
    
    # Cache for 60 seconds
    redis.setex(f"likes:{post_id}", 60, total)
    return total
```

### Solution 2: Write-through Counter

```
Keep running total in fast storage:

Write path:
1. Increment shard (DB)
2. Increment total (Redis) INCR

Read path:
1. Read from Redis (O(1))

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Shards (DB)  â”‚     â”‚        Redis             â”‚
â”‚ [100] [99]   â”‚     â”‚ post:123:likes = 1000000 â”‚
â”‚ [101] [100]  â”‚     â”‚                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                       â–²
       â””â”€â”€ Increment both â”€â”€â”€â”€â”€â”˜
```

### Solution 3: Approximate Counting

```
For display purposes, exact count not needed:

Display: "1.2M likes" instead of "1,234,567 likes"

Can use:
â”œâ”€â”€ Probabilistic counters (HyperLogLog for unique)
â”œâ”€â”€ Cached values with longer TTL
â”œâ”€â”€ Batch updates (aggregate every minute)
â””â”€â”€ Acceptable staleness (30 sec lag OK)
```

---

## ğŸ”§ Implementation Patterns

### Database Schema

```sql
-- Sharded counters table
CREATE TABLE counters (
    entity_type VARCHAR(50),   -- 'post', 'video', etc.
    entity_id BIGINT,
    shard_id SMALLINT,
    count BIGINT DEFAULT 0,
    updated_at TIMESTAMP,
    PRIMARY KEY (entity_type, entity_id, shard_id)
);

-- Index for aggregation
CREATE INDEX idx_counters_entity 
ON counters(entity_type, entity_id);
```

### Redis Sharded Counter

```python
import redis

NUM_SHARDS = 100

def increment(entity_id, amount=1):
    shard = random.randint(0, NUM_SHARDS - 1)
    key = f"counter:{entity_id}:shard:{shard}"
    return redis.incrby(key, amount)

def get_total(entity_id):
    keys = [f"counter:{entity_id}:shard:{i}" 
            for i in range(NUM_SHARDS)]
    
    # MGET is atomic and fast
    values = redis.mget(keys)
    return sum(int(v or 0) for v in values)
```

### With Lua Script (Atomic)

```lua
-- Redis Lua script for increment + get approximate total
local entity_id = KEYS[1]
local shard = math.random(0, 99)
local shard_key = "counter:" .. entity_id .. ":shard:" .. shard

-- Increment shard
redis.call('INCRBY', shard_key, 1)

-- Return cached total (may be stale)
local total_key = "counter:" .. entity_id .. ":total"
local total = redis.call('GET', total_key)

if total then
    return tonumber(total)
else
    -- Compute and cache
    local sum = 0
    for i = 0, 99 do
        local k = "counter:" .. entity_id .. ":shard:" .. i
        local v = redis.call('GET', k)
        sum = sum + (tonumber(v) or 0)
    end
    redis.call('SETEX', total_key, 60, sum)  -- Cache 60s
    return sum
end
```

---

## ğŸ’¡ Real-World Examples

### Facebook Likes

```
When post goes viral:
1. Detect high write rate
2. Dynamically increase shards
3. Use approximate counts for display
4. Aggregate exact count asynchronously

Tiered approach:
â”œâ”€â”€ Normal: 10 shards
â”œâ”€â”€ Popular: 100 shards  
â”œâ”€â”€ Viral: 1000+ shards
â””â”€â”€ Cache aggressively
```

### YouTube View Counts

```
Combination of techniques:
â”œâ”€â”€ Sharded writes to counter shards
â”œâ”€â”€ Batch processing (aggregate hourly)
â”œâ”€â”€ Cached display values
â”œâ”€â”€ Eventual consistency (a few min lag OK)
â””â”€â”€ Fraud detection before counting
```

### Twitter Likes/Retweets

```
Fan-out considerations:
â”œâ”€â”€ Counter per tweet (sharded)
â”œâ”€â”€ User sees aggregate
â”œâ”€â”€ Celebrity tweets get more shards
â””â”€â”€ Rate limiting per user
```

---

## âš ï¸ Edge Cases

### Counter Accuracy

```
Problem: Writes can fail after cache but before DB

Solutions:
â”œâ”€â”€ Use transactions where possible
â”œâ”€â”€ Accept eventual consistency
â”œâ”€â”€ Periodic reconciliation
â””â”€â”€ Idempotent writes with dedup
```

### Decrement and Negative Values

```
Problem: Unlike/remove vote

Can't just decrement - may go negative during race:
â”œâ”€â”€ User unlikes
â”œâ”€â”€ Meanwhile: aggregation runs
â”œâ”€â”€ Shard shows negative

Solution:
â”œâ”€â”€ Store likes and unlikes separately
â”œâ”€â”€ Net = likes - unlikes
â”œâ”€â”€ Or use signed integers, validate on read
```

### Shard Rebalancing

```
Problem: Need more shards for hot content

Solutions:
â”œâ”€â”€ Pre-allocate more shards (unused shards = 0)
â”œâ”€â”€ Dynamic sharding based on rate
â”œâ”€â”€ Split existing shards
â””â”€â”€ Background migration
```

---

## ğŸ’¡ In System Design Interviews

### When to Use

```
1. "How do you handle millions of likes per second?"
2. "Design a view counter for YouTube"
3. "How do you count votes in real-time?"
4. "Flash sale inventory decrement"
```

### Key Points

```
1. Why shard? Single counter = hot spot = bottleneck
2. How many shards? ~100, scale based on traffic
3. Shard selection: Random or hash-based
4. Read optimization: Cache the total
5. Trade-offs: Exact vs approximate, latency vs consistency
6. Scaling: Add more shards for viral content
```

---

## âœ… Key Takeaways

1. **Single counter = bottleneck** under high load
2. **Shard writes** across multiple rows
3. **Random selection** for even distribution
4. **Sum on read** or cache the total
5. **10-100 shards** is typical starting point
6. **Approximate is OK** for display ("1.2M likes")
7. **Redis INCR** for simple, fast sharding
8. **Combine with caching** for read optimization

---

## ğŸ“– Next Steps

Building Blocks complete! Continue to [Design Problems](../05-Design-Problems/README.md)
