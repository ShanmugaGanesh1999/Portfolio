# Key-Value Stores

> Simple, fast, and scalable data storage

---

## ðŸ“– What is a Key-Value Store?

A **Key-Value Store** is the simplest type of database that stores data as pairs of keys and values, like a giant hash map.

```
Key                    Value
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
user:123               {"name": "Alice", "age": 30}
session:abc123         {"user_id": 123, "expires": 1234567890}
cache:homepage         "<html>...</html>"
counter:page_views     42000000
```

---

## ðŸŽ¯ Why Use Key-Value Stores?

1. **Speed** - Sub-millisecond latency
2. **Simplicity** - Simple API (GET, SET, DELETE)
3. **Scalability** - Easy horizontal scaling
4. **Flexibility** - Value can be any data type

---

## ðŸ”§ Basic Operations

```python
# SET - Store a value
kv.set("user:123", {"name": "Alice"})

# GET - Retrieve a value
user = kv.get("user:123")

# DELETE - Remove a value
kv.delete("user:123")

# EXISTS - Check if key exists
exists = kv.exists("user:123")

# TTL - Set expiration
kv.set("session:abc", data, ttl=3600)  # Expires in 1 hour
```

---

## ðŸ“Š Popular Key-Value Stores

### Redis

```
Type: In-memory with optional persistence
Speed: ~100,000 operations/second
Features: Data structures, pub/sub, Lua scripting

Best for:
â”œâ”€â”€ Caching
â”œâ”€â”€ Session storage
â”œâ”€â”€ Real-time leaderboards
â”œâ”€â”€ Rate limiting
â””â”€â”€ Pub/sub messaging
```

### Memcached

```
Type: Pure in-memory cache
Speed: ~100,000+ operations/second
Features: Simple, multi-threaded

Best for:
â”œâ”€â”€ Simple caching
â”œâ”€â”€ Session storage
â””â”€â”€ When you don't need persistence
```

### DynamoDB (AWS)

```
Type: Managed, persistent
Speed: Single-digit millisecond
Features: Auto-scaling, global tables

Best for:
â”œâ”€â”€ Serverless applications
â”œâ”€â”€ Gaming leaderboards
â”œâ”€â”€ IoT data
â””â”€â”€ When you need managed service
```

### etcd

```
Type: Distributed, consistent
Features: Strong consistency, watch API

Best for:
â”œâ”€â”€ Configuration storage
â”œâ”€â”€ Service discovery
â”œâ”€â”€ Distributed locks
â””â”€â”€ Kubernetes metadata
```

---

## ðŸ—ï¸ Designing a Key-Value Store

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       Clients                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Load Balancer                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                â–¼                â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Node 1   â”‚   â”‚  Node 2   â”‚   â”‚  Node 3   â”‚
   â”‚           â”‚   â”‚           â”‚   â”‚           â”‚
   â”‚  Partitionâ”‚   â”‚  Partitionâ”‚   â”‚  Partitionâ”‚
   â”‚   A, B    â”‚   â”‚   C, D    â”‚   â”‚   E, F    â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Components

#### 1. Data Partitioning

```
How to distribute keys across nodes?

Consistent Hashing:
â”œâ”€â”€ Map keys and nodes to a hash ring
â”œâ”€â”€ Key assigned to first node clockwise
â”œâ”€â”€ Adding/removing nodes moves minimal keys

Example:
hash("user:123") = position on ring
Find first node clockwise â†’ Node 2
```

#### 2. Replication

```
Replicate data for fault tolerance

         Write
           â”‚
           â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”
       â”‚Node A â”‚ (Primary)
       â””â”€â”€â”€â”¬â”€â”€â”€â”˜
     â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
     â–¼           â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”
 â”‚Node B â”‚   â”‚Node C â”‚ (Replicas)
 â””â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”˜
 
 N = 3 replicas
 Survive 2 failures
```

#### 3. Consistency

```
Quorum System:
â”œâ”€â”€ N = Total replicas
â”œâ”€â”€ W = Write quorum (successful writes needed)
â”œâ”€â”€ R = Read quorum (successful reads needed)

Strong consistency: W + R > N
â”œâ”€â”€ Example: N=3, W=2, R=2
â”œâ”€â”€ Always see latest write

Eventual consistency: W + R <= N
â”œâ”€â”€ Example: N=3, W=1, R=1
â”œâ”€â”€ Faster, but may see stale data
```

#### 4. Conflict Resolution

```
When replicas disagree, how to resolve?

Last-Write-Wins (LWW):
â”œâ”€â”€ Attach timestamp to each write
â”œâ”€â”€ Latest timestamp wins
â””â”€â”€ Simple but can lose data

Vector Clocks:
â”œâ”€â”€ Track causal history
â”œâ”€â”€ Detect conflicts
â””â”€â”€ Let application resolve

CRDTs (Conflict-free):
â”œâ”€â”€ Data structures that merge automatically
â”œâ”€â”€ Counters, sets, maps
â””â”€â”€ No conflicts possible
```

---

## ðŸ“ˆ Scalability Features

### Consistent Hashing

```
Add/Remove nodes with minimal data movement

        Node A                    Node A
           â”‚                         â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
    â”‚  Hash Ring â”‚    â”€â”€â–º     â”‚  Hash Ring â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â•±              â•²          â•±    â”‚         â•²
Node D          Node B     Node D â”‚       Node B
                                  â”‚
                              Node E (new)
                              
Only keys between D and E move to E
```

### Virtual Nodes

```
Problem: Uneven distribution with few nodes

Solution: Each physical node = many virtual nodes

Physical Node 1 â†’ V1, V4, V7
Physical Node 2 â†’ V2, V5, V8
Physical Node 3 â†’ V3, V6, V9

Better distribution!
```

---

## ðŸ›¡ï¸ Fault Tolerance

### Failure Detection

```
Gossip Protocol:
â”œâ”€â”€ Nodes periodically exchange state
â”œâ”€â”€ "Have you heard from Node B?"
â”œâ”€â”€ If no one has â†’ Mark as failed
â”œâ”€â”€ Decentralized, scalable
```

### Handling Failures

```
Hinted Handoff:
â”œâ”€â”€ Node A handles write for failed Node B
â”œâ”€â”€ Stores "hint" to forward later
â”œâ”€â”€ When B recovers, A sends data
â””â”€â”€ Temporary coverage during outage

Read Repair:
â”œâ”€â”€ Read from multiple replicas
â”œâ”€â”€ If values differ, repair stale replicas
â”œâ”€â”€ Background consistency
```

---

## ðŸ’¡ Key-Value Store Patterns

### Caching Pattern

```python
def get_user(user_id):
    # Try cache first
    cached = redis.get(f"user:{user_id}")
    if cached:
        return json.loads(cached)
    
    # Cache miss - fetch from DB
    user = database.get_user(user_id)
    
    # Store in cache for next time
    redis.set(f"user:{user_id}", json.dumps(user), ex=3600)
    
    return user
```

### Counter Pattern

```python
# Atomic increment (no race conditions)
redis.incr("page_views")
redis.incrby("likes:post:123", 1)

# Get current count
views = redis.get("page_views")
```

### Rate Limiting Pattern

```python
def is_rate_limited(user_id, limit=100, window=60):
    key = f"rate:{user_id}:{current_minute()}"
    
    count = redis.incr(key)
    if count == 1:
        redis.expire(key, window)
    
    return count > limit
```

### Session Storage Pattern

```python
def create_session(user_id):
    session_id = generate_uuid()
    session_data = {"user_id": user_id, "created": now()}
    
    redis.set(f"session:{session_id}", json.dumps(session_data), ex=86400)
    return session_id

def get_session(session_id):
    data = redis.get(f"session:{session_id}")
    return json.loads(data) if data else None
```

---

## âš ï¸ Key-Value Store Limitations

```
1. No Complex Queries
   âœ— Cannot do: SELECT * FROM users WHERE age > 25
   âœ“ Can only do: GET user:123

2. No Relationships
   âœ— No JOINs between tables
   âœ“ Must denormalize or query multiple keys

3. Limited Transaction Support
   âœ— No multi-key ACID transactions (usually)
   âœ“ Some support Lua scripting for atomicity

4. Memory Constraints
   âœ— In-memory stores limited by RAM
   âœ“ Use eviction policies, or disk-based stores
```

---

## ðŸ“Š Redis vs Memcached

| Feature | Redis | Memcached |
|---------|-------|-----------|
| Data Structures | Yes (lists, sets, hashes) | No (strings only) |
| Persistence | Yes | No |
| Replication | Yes | No |
| Clustering | Yes | Client-side |
| Pub/Sub | Yes | No |
| Lua Scripting | Yes | No |
| Multi-threaded | No (single-threaded) | Yes |

**Choose Redis when**: You need data structures, persistence, or pub/sub
**Choose Memcached when**: Simple caching, multi-threaded performance

---

## ðŸ’¡ In System Design Interviews

### Common Use Cases to Mention

```
1. "We'll use Redis for caching to reduce database load"
2. "Session storage in Redis for stateless web servers"
3. "Rate limiting with Redis counters"
4. "Real-time leaderboard using Redis sorted sets"
5. "Distributed locks with Redis for coordination"
```

### Design Questions to Consider

```
â”œâ”€â”€ In-memory or persistent?
â”œâ”€â”€ What's the eviction policy?
â”œâ”€â”€ How many replicas?
â”œâ”€â”€ Consistency requirements?
â”œâ”€â”€ TTL for cached items?
â””â”€â”€ Estimated memory requirements?
```

---

## âœ… Key Takeaways

1. **Simple API** - GET, SET, DELETE
2. **Blazing fast** - Sub-millisecond latency
3. **Great for caching** - Reduce database load
4. **Scales horizontally** - Consistent hashing + sharding
5. **Limited queries** - Only key-based lookups
6. **Redis is versatile** - Data structures, pub/sub, persistence
7. **Consider memory** - In-memory stores need enough RAM

---

## ðŸ“– Next Steps

â†’ Continue to [CDN](./05-cdn.md)
