# Distributed Monitoring

> Observing system health, performance, and behavior

---

## ğŸ“– What is Distributed Monitoring?

**Distributed Monitoring** is the practice of collecting, storing, and visualizing metrics, traces, and health data from all components of a distributed system.

```
The Three Pillars of Observability:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Observability                           â”‚
â”‚                                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚   â”‚   Metrics   â”‚   â”‚    Logs     â”‚   â”‚   Traces    â”‚       â”‚
â”‚   â”‚             â”‚   â”‚             â”‚   â”‚             â”‚       â”‚
â”‚   â”‚  Numbers    â”‚   â”‚   Events    â”‚   â”‚   Request   â”‚       â”‚
â”‚   â”‚  over time  â”‚   â”‚   text      â”‚   â”‚   flow      â”‚       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                              â”‚
â”‚   "CPU is 80%"      "Error at X"    "Request took           â”‚
â”‚                                       100ms across           â”‚
â”‚                                       3 services"            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Why Monitoring?

```
Without Monitoring:
â”œâ”€â”€ "Is the system healthy?" â†’ "I think so?"
â”œâ”€â”€ "Why is it slow?" â†’ "Let me check logs..."
â”œâ”€â”€ "When did it break?" â†’ "Users complained 2 hours ago"
â””â”€â”€ Firefighting mode

With Monitoring:
â”œâ”€â”€ Proactive alerting before users notice
â”œâ”€â”€ Dashboards show system health at a glance
â”œâ”€â”€ Historical data for trend analysis
â”œâ”€â”€ Root cause analysis with metrics
â””â”€â”€ Capacity planning with data
```

---

## ğŸ”§ Types of Metrics

### The Four Golden Signals

```
Google SRE's recommended metrics:

1. Latency
   â”œâ”€â”€ How long requests take
   â””â”€â”€ p50, p95, p99 percentiles

2. Traffic
   â”œâ”€â”€ How much demand
   â””â”€â”€ Requests/second, concurrent users

3. Errors
   â”œâ”€â”€ Rate of failed requests
   â””â”€â”€ HTTP 5xx rate, exception count

4. Saturation
   â”œâ”€â”€ How "full" the system is
   â””â”€â”€ CPU%, memory%, queue depth
```

### RED Method (Request-focused)

```
For microservices:

R - Rate:     Requests per second
E - Errors:   Failed requests per second
D - Duration: Request latency distribution
```

### USE Method (Resource-focused)

```
For infrastructure:

U - Utilization: % time resource is busy
S - Saturation:  Queue length, waiting
E - Errors:      Error count
```

---

## ğŸ“Š Metrics Architecture

### Pull vs Push Model

```
Pull Model (Prometheus):
â”œâ”€â”€ Monitoring server scrapes targets
â”œâ”€â”€ Targets expose /metrics endpoint
â”œâ”€â”€ Server controls scrape interval
â””â”€â”€ Simpler for dynamic environments

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     scrape      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Prometheus  â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚   Service    â”‚
â”‚              â”‚     /metrics    â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Push Model (StatsD, InfluxDB):
â”œâ”€â”€ Services push metrics to collector
â”œâ”€â”€ Works behind firewalls
â”œâ”€â”€ Better for short-lived processes
â””â”€â”€ Higher volume support

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     push        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Service    â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Collector   â”‚
â”‚              â”‚                 â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Prometheus Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Monitoring Stack                         â”‚
â”‚                                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚   â”‚Service Aâ”‚    â”‚Service Bâ”‚    â”‚Service Câ”‚                 â”‚
â”‚   â”‚ /metricsâ”‚    â”‚ /metricsâ”‚    â”‚ /metricsâ”‚                 â”‚
â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                 â”‚
â”‚        â”‚              â”‚              â”‚                       â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                       â–¼                                      â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚              â”‚   Prometheus   â”‚                              â”‚
â”‚              â”‚  (scrape/store)â”‚                              â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                      â”‚                                       â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚          â–¼           â–¼           â–¼                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚   â”‚  Grafana  â”‚ â”‚Alertmanagerâ”‚ â”‚  PromQL   â”‚                 â”‚
â”‚   â”‚(dashboard)â”‚ â”‚  (alerts) â”‚ â”‚ (queries) â”‚                 â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Metric Types

### Counter

```
Only goes up (resets on restart)

Use for: Requests, errors, completed tasks

http_requests_total{method="GET", path="/api"} 12345

Rate calculation:
rate(http_requests_total[5m]) = requests per second
```

### Gauge

```
Goes up and down

Use for: Current values, temperatures, queue sizes

memory_usage_bytes 1073741824
active_connections 42
```

### Histogram

```
Distribution of values in buckets

Use for: Latencies, request sizes

http_request_duration_seconds_bucket{le="0.1"} 1000
http_request_duration_seconds_bucket{le="0.5"} 1800
http_request_duration_seconds_bucket{le="1"}   1950
http_request_duration_seconds_bucket{le="+Inf"} 2000

Calculate percentiles:
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))
```

### Summary

```
Pre-calculated quantiles (client-side)

Use for: When you know needed percentiles upfront

http_request_duration_seconds{quantile="0.5"} 0.05
http_request_duration_seconds{quantile="0.95"} 0.2
http_request_duration_seconds{quantile="0.99"} 0.5
```

---

## ğŸ“ˆ Implementing Metrics

### Application Metrics (Python Example)

```python
from prometheus_client import Counter, Histogram, Gauge, start_http_server
import time

# Define metrics
REQUEST_COUNT = Counter(
    'http_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status']
)

REQUEST_LATENCY = Histogram(
    'http_request_duration_seconds',
    'HTTP request latency',
    ['endpoint'],
    buckets=[.01, .05, .1, .25, .5, 1, 2.5, 5, 10]
)

ACTIVE_REQUESTS = Gauge(
    'http_requests_active',
    'Active HTTP requests'
)

# Use in application
def handle_request(method, endpoint):
    ACTIVE_REQUESTS.inc()
    start_time = time.time()
    
    try:
        # Process request
        result = process()
        REQUEST_COUNT.labels(method, endpoint, '200').inc()
        return result
    except Exception:
        REQUEST_COUNT.labels(method, endpoint, '500').inc()
        raise
    finally:
        ACTIVE_REQUESTS.dec()
        REQUEST_LATENCY.labels(endpoint).observe(time.time() - start_time)

# Start metrics endpoint
start_http_server(8000)  # /metrics on port 8000
```

### Infrastructure Metrics

```yaml
# Node Exporter for system metrics
node_cpu_seconds_total
node_memory_MemAvailable_bytes
node_disk_io_time_seconds_total
node_network_receive_bytes_total

# Kubernetes metrics
kube_pod_status_ready
kube_deployment_status_replicas_available
container_cpu_usage_seconds_total
container_memory_usage_bytes
```

---

## ğŸ”§ Alerting

### Alert Rules

```yaml
# Prometheus alerting rules
groups:
  - name: example
    rules:
      - alert: HighErrorRate
        expr: |
          sum(rate(http_requests_total{status=~"5.."}[5m])) 
          / sum(rate(http_requests_total[5m])) > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }}"
      
      - alert: HighLatency
        expr: |
          histogram_quantile(0.95, 
            rate(http_request_duration_seconds_bucket[5m])
          ) > 1
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "P95 latency is above 1 second"
```

### Alert Best Practices

```
Good Alerts:
â”œâ”€â”€ Actionable (someone can fix it)
â”œâ”€â”€ Urgent (needs attention now)
â”œâ”€â”€ Rare (not noisy)
â””â”€â”€ Clear (what's wrong, how to fix)

Bad Alerts:
â”œâ”€â”€ Too sensitive (alert fatigue)
â”œâ”€â”€ Not actionable (so what?)
â”œâ”€â”€ No context (what service? what impact?)
â””â”€â”€ Duplicates (same issue, many alerts)

Structure:
â”œâ”€â”€ Page (wake someone up): System down
â”œâ”€â”€ Ticket (fix tomorrow): Degraded performance
â”œâ”€â”€ Log (informational): Unusual but ok
```

---

## ğŸ“Š Dashboards

### Dashboard Design

```
Executive Dashboard:
â”œâ”€â”€ Overall system health (green/yellow/red)
â”œâ”€â”€ Key business metrics
â”œâ”€â”€ SLA compliance
â””â”€â”€ High-level trends

Service Dashboard:
â”œâ”€â”€ Request rate, error rate, latency
â”œâ”€â”€ Resource usage (CPU, memory)
â”œâ”€â”€ Dependencies health
â”œâ”€â”€ Recent deployments marker

Debugging Dashboard:
â”œâ”€â”€ Detailed breakdowns
â”œâ”€â”€ Individual endpoint metrics
â”œâ”€â”€ Queue depths
â”œâ”€â”€ Database query times
```

### Grafana Dashboard Example

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Service: User API                                    ğŸŸ¢     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Requests/s   â”‚  â”‚  Error Rate    â”‚  â”‚  P95 Latency   â”‚ â”‚
â”‚  â”‚                â”‚  â”‚                â”‚  â”‚                â”‚ â”‚
â”‚  â”‚     1,234      â”‚  â”‚     0.1%       â”‚  â”‚     45ms       â”‚ â”‚
â”‚  â”‚    â–â–ƒâ–…â–‡â–…â–ƒâ–    â”‚  â”‚    â–â–â–â–‚â–â–â–    â”‚  â”‚    â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    Request Rate                         â”‚ â”‚
â”‚  â”‚  â–â–‚â–ƒâ–…â–‡â–…â–ƒâ–‚â–â–‚â–ƒâ–…â–‡â–…â–ƒâ–‚â–â–‚â–ƒâ–…â–‡â–…â–ƒâ–‚â–â–‚â–ƒâ–…â–‡â–…â–ƒâ–‚â–                    â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º   â”‚ â”‚
â”‚  â”‚   00:00        06:00        12:00        18:00  Now     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Distributed Tracing

### What is Tracing?

```
Track a request across multiple services:

User Request
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ API Gateway â”‚â”€â”€â”€â–ºâ”‚User Service â”‚â”€â”€â”€â–ºâ”‚  Database   â”‚
â”‚   (50ms)    â”‚    â”‚   (30ms)    â”‚    â”‚   (20ms)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚Cache Serviceâ”‚
                   â”‚   (5ms)     â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Total: 105ms (but where's the bottleneck?)
Trace shows: Most time in API Gateway (50ms)
```

### Trace Structure

```
Trace: A complete request flow (trace_id)
Span: A single operation within trace (span_id)

Trace ID: abc-123
â”œâ”€â”€ Span: API Gateway (parent=none)
â”‚   â”œâ”€â”€ start: 0ms
â”‚   â”œâ”€â”€ end: 50ms
â”‚   â””â”€â”€ tags: {method: GET, path: /users/1}
â”œâ”€â”€ Span: User Service (parent=API Gateway)
â”‚   â”œâ”€â”€ start: 50ms
â”‚   â”œâ”€â”€ end: 80ms
â”‚   â””â”€â”€ tags: {user_id: 1}
â”œâ”€â”€ Span: Database Query (parent=User Service)
â”‚   â”œâ”€â”€ start: 55ms
â”‚   â”œâ”€â”€ end: 75ms
â”‚   â””â”€â”€ tags: {query: SELECT...}
â””â”€â”€ Span: Cache Lookup (parent=User Service)
    â”œâ”€â”€ start: 80ms
    â”œâ”€â”€ end: 85ms
    â””â”€â”€ tags: {hit: true}
```

### Tracing Tools

```
Jaeger (CNCF):
â”œâ”€â”€ Open source
â”œâ”€â”€ Native Kubernetes support
â”œâ”€â”€ Good for microservices

Zipkin:
â”œâ”€â”€ Originally from Twitter
â”œâ”€â”€ Simple, mature
â”œâ”€â”€ Wide language support

AWS X-Ray:
â”œâ”€â”€ Native AWS integration
â”œâ”€â”€ Managed service
â”œâ”€â”€ Good for AWS workloads

OpenTelemetry:
â”œâ”€â”€ Unified standard
â”œâ”€â”€ Vendor neutral
â”œâ”€â”€ Future of observability
â””â”€â”€ Combines traces, metrics, logs
```

---

## ğŸ“ˆ Monitoring Technologies

### Time-Series Databases

```
Prometheus:
â”œâ”€â”€ Pull-based
â”œâ”€â”€ PromQL query language
â”œâ”€â”€ Good for Kubernetes
â”œâ”€â”€ Local storage (limited retention)

InfluxDB:
â”œâ”€â”€ Push-based
â”œâ”€â”€ Flux query language
â”œâ”€â”€ Better for IoT, high cardinality

TimescaleDB:
â”œâ”€â”€ PostgreSQL extension
â”œâ”€â”€ SQL queries
â”œâ”€â”€ Good for existing SQL users

VictoriaMetrics:
â”œâ”€â”€ Prometheus compatible
â”œâ”€â”€ Better performance/compression
â”œâ”€â”€ Long-term storage
```

### Managed Services

```
Datadog:
â”œâ”€â”€ All-in-one (metrics, logs, traces)
â”œâ”€â”€ Excellent UX
â”œâ”€â”€ Expensive at scale

New Relic:
â”œâ”€â”€ APM focused
â”œâ”€â”€ Good for application monitoring
â”œâ”€â”€ Full-stack observability

AWS CloudWatch:
â”œâ”€â”€ Native AWS integration
â”œâ”€â”€ Basic but sufficient
â”œâ”€â”€ Pay per metric/alarm

Grafana Cloud:
â”œâ”€â”€ Managed Grafana + Prometheus
â”œâ”€â”€ Open source friendly
â”œâ”€â”€ Good pricing
```

---

## ğŸ’¡ Monitoring Best Practices

### What to Monitor

```
Application Layer:
â”œâ”€â”€ Request rate, error rate, latency
â”œâ”€â”€ Business metrics (orders, signups)
â”œâ”€â”€ Feature flag usage
â””â”€â”€ Cache hit rates

Infrastructure Layer:
â”œâ”€â”€ CPU, memory, disk, network
â”œâ”€â”€ Container health
â”œâ”€â”€ Pod restarts, OOM kills
â””â”€â”€ Node availability

Dependencies:
â”œâ”€â”€ Database connections, query times
â”œâ”€â”€ External API latency
â”œâ”€â”€ Message queue depth
â””â”€â”€ Third-party service health
```

### Labeling Strategy

```
Good labels:
â”œâ”€â”€ service: "user-api"
â”œâ”€â”€ environment: "production"
â”œâ”€â”€ version: "v1.2.3"
â”œâ”€â”€ endpoint: "/api/users"
â”œâ”€â”€ method: "GET"
â””â”€â”€ status_code: "200"

Avoid high cardinality:
â”œâ”€â”€ user_id (millions of values)
â”œâ”€â”€ request_id (unique per request)
â”œâ”€â”€ timestamp in label
â””â”€â”€ These explode metric storage!
```

---

## ğŸ’¡ In System Design Interviews

### When to Discuss

```
1. "How do you know if the system is healthy?"
2. "How do you detect and debug issues?"
3. "What happens when things go wrong?"
4. "How do you ensure SLAs?"
```

### Key Points

```
1. Three pillars: Metrics, Logs, Traces
2. Four golden signals: Latency, Traffic, Errors, Saturation
3. Prometheus + Grafana is common stack
4. Alert on symptoms, not causes
5. Correlation IDs link everything together
6. SLIs/SLOs for reliability targets
```

---

## âœ… Key Takeaways

1. **Three pillars**: Metrics, Logs, Traces
2. **Four golden signals**: Latency, Traffic, Errors, Saturation
3. **Prometheus** is the standard for metrics
4. **Grafana** for visualization
5. **Distributed tracing** for request flow
6. **Alert on symptoms** (high latency) not causes (CPU)
7. **Avoid high cardinality** labels
8. **Dashboards** for different audiences
